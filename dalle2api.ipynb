{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    #inside infinity loop\n",
    "    ret, frame = vid.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    print(ret)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    cv2.imwrite('frame.jpg', frame)\n",
    "\n",
    "\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def resize_image(image):\n",
    "    # Load the input image\n",
    "    input_image = cv2.imread(image)\n",
    "\n",
    "    # Get the dimensions of the input image\n",
    "    original_height, original_width = input_image.shape[:2]\n",
    "\n",
    "    # Determine the maximum dimension for resizing\n",
    "    max_dim = max(original_height, original_width)\n",
    "    size = 1024\n",
    "    # Calculate the scaling factor to resize the image while preserving the aspect ratio\n",
    "    scale_factor = size / max_dim\n",
    "\n",
    "    # Resize the image using the scaling factor\n",
    "    resized_image = cv2.resize(input_image, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "    # Get the new dimensions of the resized image\n",
    "    resized_height, resized_width = resized_image.shape[:2]\n",
    "\n",
    "    # Calculate the padding needed to make the image 1024x1024\n",
    "    top_pad = (size - resized_height) // 2\n",
    "    bottom_pad = size - resized_height - top_pad\n",
    "    left_pad = (size - resized_width) // 2\n",
    "    right_pad = size - resized_width - left_pad\n",
    "\n",
    "    # Pad the image with black spaces\n",
    "    resized_image = cv2.copyMakeBorder(resized_image, top_pad, bottom_pad, left_pad, right_pad, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    cv2.imwrite(\"resized_image.png\", resized_image)\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "resize_image(\"frame.jpg\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_mask(resized_image):\n",
    "    # Convert the image to grayscale\n",
    "    resized_image = cv2.imread(resized_image)\n",
    "    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Face detection using a pre-trained model (e.g., Haar cascades or MTCNN)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray_image, minNeighbors=1, minSize=(50, 50))\n",
    "\n",
    "    # Initialize an empty mask\n",
    "    mask = np.zeros_like(gray_image)\n",
    "\n",
    "    # Iterate over detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Calculate the new bounding box dimensions to make the mask smaller\n",
    "        new_x = int(x-0.1*x)  # Adjust the scaling factor as needed\n",
    "        new_y = int(y - 0.3 * h)\n",
    "        new_w = int(1.3* w)\n",
    "        new_h = int(1.4*h)\n",
    "\n",
    "        # Generate a mask for the adjusted face ROI\n",
    "        mask[new_y:new_y+new_h, new_x:new_x+new_w] = 255\n",
    "\n",
    "    inverted_mask = mask\n",
    "    cv2.imwrite(\"mask.png\", inverted_mask)\n",
    "    return inverted_mask\n",
    "\n",
    "create_mask(\"resized_image.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Image(b64_json=None, revised_prompt=None, url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-dlYehfj4QTfsDTiH4DtZ7re2/user-j2arhmwNBpJkZTfQc0BorUv3/img-W2xohkiRS0zvaPACZYZmGLXs.png?st=2024-05-13T07%3A56%3A54Z&se=2024-05-13T09%3A56%3A54Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-12T22%3A51%3A12Z&ske=2024-05-13T22%3A51%3A12Z&sks=b&skv=2021-08-06&sig=3s1lfC0MKnEX43bh%2BY0r5pgtkkxgjR2e0I7iEigpmJQ%3D')]\n"
     ]
    }
   ],
   "source": [
    "def create_image(dim, num):\n",
    "\n",
    "    # OpenAI request\n",
    "    client = openai.Client(api_key=\"xxxxxxxxxx\")\n",
    "\n",
    "    response = client.images.edit(\n",
    "        model=\"dall-e-2\",\n",
    "        image=open(\"resized_image.png\", \"rb\"),\n",
    "        mask=open(\"mask.png\", \"rb\"),\n",
    "        prompt=\"change the background to a forest, and add some magical equipment like a wand and a spellbook for the person, be detailed and realistic\",\n",
    "        n=num,\n",
    "        size=dim,\n",
    "    )\n",
    "    # Get the edited image URL\n",
    "    image_url = response.data\n",
    "    return image_url\n",
    "\n",
    "\n",
    "print(create_image(\"1024x1024\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
